{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mnist import MNIST\n",
    "\n",
    "# mnist = MNIST('/home/bnapp/datasets/mnist/')\n",
    "# images, labels = mnist.load_training()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import importlib\n",
    "importlib.reload(misc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Convolutional Neural Network.\n",
    "Build and train a convolutional neural network with TensorFlow.\n",
    "This example is using the MNIST database of handwritten digits\n",
    "(http://yann.lecun.com/exdb/mnist/)\n",
    "This example is using TensorFlow layers API, see 'convolutional_network_raw' \n",
    "example for a raw implementation with variables.\n",
    "Author: Aymeric Damien - modified by Alexander Rivkind\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 100\n",
    "batch_size = 128\n",
    "\n",
    "# Network Parameters\n",
    "size=(28,28)\n",
    "padding_size=(56,56)\n",
    "num_input = padding_size[0]*padding_size[1] # MNIST data input (img shape: 28*28)\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.25 # Dropout, probability to drop a unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_mnist_mat(image_mat,size=(28,28),orig_size=(28,28),padding=(28,28),offset=(0,0)):\n",
    "    o=np.zeros([np.shape(image_mat)[0]]+list(padding))\n",
    "    for ii,image in enumerate(image_mat):\n",
    "        img_sc=cv2.resize(0.0+np.reshape(image,list(orig_size)), dsize=size)\n",
    "        #todo: x/y row/column convention\n",
    "        o[ii,:]=misc.build_mnist_padded([img_sc],y_size=size[1],x_size=size[0],xx=padding[0],yy=padding[1],offset=offset)\n",
    "    return o    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train = scale_mnist_mat(mnist.train.images,padding=padding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test = scale_mnist_mat(mnist.test.images,padding=padding_size)\n",
    "scaled_test_2x = scale_mnist_mat(mnist.test.images,padding=padding_size,size=(56,56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test_1p5x = scale_mnist_mat(mnist.test.images,padding=padding_size,size=(42,42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpxhnf9jfh\n",
      "INFO:tensorflow:Using config: {'_device_fn': None, '_master': '', '_task_type': 'worker', '_tf_random_seed': None, '_num_worker_replicas': 1, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f84c1616710>, '_protocol': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_save_checkpoints_steps': None, '_global_id_in_cluster': 0, '_evaluation_master': '', '_num_ps_replicas': 0, '_is_chief': True, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpxhnf9jfh', '_experimental_distribute': None, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_task_id': 0, '_eval_distribute': None, '_train_distribute': None}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpxhnf9jfh/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.2978097769770387, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmpxhnf9jfh/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.1238183029754505.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-25-02:51:08\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpxhnf9jfh/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-25-02:51:16\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.9682, global_step = 100, loss = 0.10512893\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /tmp/tmpxhnf9jfh/model.ckpt-100\n",
      "Testing Accuracy: 0.9682\n"
     ]
    }
   ],
   "source": [
    "# Create the neural network\n",
    "def conv_net(x_dict, n_classes, dropout, reuse, is_training):\n",
    "    # Define a scope for reusing the variables\n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "        # TF Estimator input is a dict, in case of multiple inputs\n",
    "        x = x_dict['images']\n",
    "\n",
    "        # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n",
    "        # Reshape to match picture format [Height x Width x Channel]\n",
    "        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "        x = tf.reshape(x, shape=[-1, padding_size[0], padding_size[1], 1])\n",
    "\n",
    "        # Convolution Layer with 32 filters and a kernel size of 5\n",
    "        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "\n",
    "        # Convolution Layer with 64 filters and a kernel size of 3\n",
    "        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "\n",
    "        # Flatten the data to a 1-D vector for the fully connected layer\n",
    "        fc1 = tf.contrib.layers.flatten(conv2)\n",
    "\n",
    "        # Fully connected layer (in tf contrib folder for now)\n",
    "        fc1 = tf.layers.dense(fc1, 1024)\n",
    "        # Apply Dropout (if is_training is False, dropout is not applied)\n",
    "        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n",
    "\n",
    "        # Output layer, class prediction\n",
    "        out = tf.layers.dense(fc1, n_classes)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# Define the model function (following TF Estimator Template)\n",
    "def model_fn(features, labels, mode):\n",
    "    # Build the neural network\n",
    "    # Because Dropout have different behavior at training and prediction time, we\n",
    "    # need to create 2 distinct computation graphs that still share the same weights.\n",
    "    logits_train = conv_net(features, num_classes, dropout, reuse=False,\n",
    "                            is_training=True)\n",
    "    logits_test = conv_net(features, num_classes, dropout, reuse=True,\n",
    "                           is_training=False)\n",
    "\n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits_test, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits_test)\n",
    "\n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "\n",
    "        # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op,\n",
    "                                  global_step=tf.train.get_global_step())\n",
    "\n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "\n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=pred_classes,\n",
    "        loss=loss_op,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs\n",
    "\n",
    "# Build the Estimator\n",
    "model = tf.estimator.Estimator(model_fn)\n",
    "\n",
    "# Define the input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': scaled_train.reshape([-1,padding_size[0], padding_size[1]])}, y=mnist.train.labels,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "# Train the Model\n",
    "model.train(input_fn, steps=num_steps)\n",
    "\n",
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': scaled_test.reshape([-1,padding_size[0], padding_size[1]])}, y=mnist.test.labels,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "e = model.evaluate(input_fn)\n",
    "\n",
    "print(\"Testing Accuracy:\", e['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-25-02:53:22\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpxhnf9jfh/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-25-02:53:30\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.9682, global_step = 100, loss = 0.1050447\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /tmp/tmpxhnf9jfh/model.ckpt-100\n",
      "Testing Accuracy: 0.9682\n"
     ]
    }
   ],
   "source": [
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': scaled_test.reshape([-1,padding_size[0], padding_size[1]])}, y=mnist.test.labels,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "e = model.evaluate(input_fn)\n",
    "\n",
    "print(\"Testing Accuracy:\", e['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-25-02:53:45\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpxhnf9jfh/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-25-02:53:54\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.2271, global_step = 100, loss = 6.3314567\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /tmp/tmpxhnf9jfh/model.ckpt-100\n",
      "Testing Accuracy: 0.2271\n"
     ]
    }
   ],
   "source": [
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': scaled_test_2x.reshape([-1,padding_size[0], padding_size[1]])}, y=mnist.test.labels,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "e = model.evaluate(input_fn)\n",
    "\n",
    "print(\"Testing Accuracy:\", e['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-25-02:55:25\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpxhnf9jfh/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-25-02:55:33\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.6348, global_step = 100, loss = 1.8725779\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /tmp/tmpxhnf9jfh/model.ckpt-100\n",
      "Testing Accuracy: 0.6348\n"
     ]
    }
   ],
   "source": [
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': scaled_test_1p5x.reshape([-1,padding_size[0], padding_size[1]])}, y=mnist.test.labels,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "e = model.evaluate(input_fn)\n",
    "\n",
    "print(\"Testing Accuracy:\", e['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-25-07:12:55\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpxhnf9jfh/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-25-07:13:06\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.237, global_step = 100, loss = 2.589071\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /tmp/tmpxhnf9jfh/model.ckpt-100\n",
      "Testing Accuracy: 0.237\n"
     ]
    }
   ],
   "source": [
    "scaled_test = scale_mnist_mat(mnist.test.images,padding=padding_size,size=(14,14))\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': scaled_test.reshape([-1,padding_size[0], padding_size[1]])}, y=mnist.test.labels,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "e = model.evaluate(input_fn)\n",
    "\n",
    "print(\"Testing Accuracy:\", e['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-28-18:35:55\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpxhnf9jfh/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-28-18:36:02\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.08, global_step = 100, loss = 8.016816\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /tmp/tmpxhnf9jfh/model.ckpt-100\n",
      "Testing Accuracy: 0.08\n"
     ]
    }
   ],
   "source": [
    "scaled_test = scale_mnist_mat(mnist.test.images,padding=padding_size,size=(28,28),offset=(5,5))\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': scaled_test.reshape([-1,padding_size[0], padding_size[1]])}, y=mnist.test.labels,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "e = model.evaluate(input_fn)\n",
    "\n",
    "print(\"Testing Accuracy:\", e['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-28-18:46:00\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpxhnf9jfh/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-28-18:46:08\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.6332, global_step = 100, loss = 1.4704845\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /tmp/tmpxhnf9jfh/model.ckpt-100\n",
      "Testing Accuracy: 0.6332\n"
     ]
    }
   ],
   "source": [
    "scaled_test = scale_mnist_mat(mnist.test.images,padding=padding_size,size=(28,28),offset=(-2,-2))\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': scaled_test.reshape([-1,padding_size[0], padding_size[1]])}, y=mnist.test.labels,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "e = model.evaluate(input_fn)\n",
    "\n",
    "print(\"Testing Accuracy:\", e['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records:\n",
    "    Nominal Testing Accuracy: 0.9682\n",
    "        56x56: Testing Accuracy: 0.2271\n",
    "        14x14: Testing Accuracy: 0.237\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f84c17af128>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(scaled_test[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
