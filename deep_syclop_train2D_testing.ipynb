{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DVS128 closed loop oscillator routine by Alexander Rivkind, Eldad Assa, Michael Kreiserman and Ehud Ahissar\n",
    "based on: \n",
    "*DVS example by: Yuhuang Hu (duguyue100@gmail.com)\n",
    "*\"Syclop\" paradigm: Ahissar and Assa 2016\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import time\n",
    "import SYCLOP_env as syc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import pickle\n",
    "from RL_brain_b import DeepQNetwork\n",
    "\n",
    "import cv2\n",
    "import copy\n",
    "from misc import *\n",
    "import maestro\n",
    "import sys\n",
    "import os\n",
    "from pyaer.dvs128 import DVS128\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Free_run_agent():\n",
    "    def __init__(self,max_q = None):\n",
    "        self.hp = HP()\n",
    "        self.hp.action_space = ['v_right','v_left','v_up','v_down','null'] + \\\n",
    "                               [['v_right','v_up'],['v_right','v_down'],['v_left','v_up'],['v_left','v_down']]#'\n",
    "        self.hp.max_speed  = 10\n",
    "        self.q_centre = np.array([0.,0.], dtype='f') \n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.q_ana = np.array([0.,0.], dtype='f') \n",
    "        self.qdot = np.array([0.0,0.0])\n",
    "        self.qdotdot = np.array([0.0,0.0])\n",
    "        self.q = np.int32(np.floor(self.q_ana))\n",
    "\n",
    "    def sync_with_servo(self,servo,orientations = [0,1]):\n",
    "        for orientation in orientations:\n",
    "            if not servo.isMoving(orientation):\n",
    "                self.qdot[orientation]=0.0\n",
    "                \n",
    "            \n",
    "    def act(self,a):\n",
    "        if a is None:\n",
    "            action = 'null'\n",
    "        else:\n",
    "            action = self.hp.action_space[a]\n",
    "        #delta_a = 0.001\n",
    "        if type(action) == list:\n",
    "            for subaction in action:\n",
    "                self.parse_action(subaction)\n",
    "        else:\n",
    "            self.parse_action(action)\n",
    "\n",
    "        #print('debug', self.max_q, self.q_centre)\n",
    "        self.qdot += self.qdotdot\n",
    "        #self.qdot -= self.hp.returning_force*(self.q_ana-self.q_centre)\n",
    "        self.q_ana +=self.qdot\n",
    "        self.q = np.int32(np.floor(self.q_ana))\n",
    "\n",
    "    def parse_action(self,action):\n",
    "        if type(action)==int:\n",
    "            self.qdot[0] = action\n",
    "            self.qdotdot = np.array([0., 0.])\n",
    "        elif action == 'v_up':   # up\n",
    "            self.qdot[1] = self.qdot[1] + (1 if self.qdot[1] < self.hp.max_speed else 0)\n",
    "            self.qdotdot = np.array([0., 0.])\n",
    "        elif action == 'v_down':   # down\n",
    "            self.qdot[1] = self.qdot[1] - (1 if self.qdot[1] > -self.hp.max_speed else 0)  \n",
    "            self.qdotdot = np.array([0., 0.])\n",
    "        elif action == 'v_left':   # left\n",
    "            self.qdot[0] = self.qdot[0] - (1 if self.qdot[0] > -self.hp.max_speed else 0)  \n",
    "            self.qdotdot = np.array([0., 0.])\n",
    "        elif action == 'v_right':   # right\n",
    "            self.qdot[0] = self.qdot[0] + (1 if self.qdot[0] < self.hp.max_speed else 0) \n",
    "            self.qdotdot = np.array([0.,0.])\n",
    "        elif action == 'null':   # null\n",
    "            pass\n",
    "        else:\n",
    "            error('unknown action')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    hp = HP()\n",
    "    hp.mem_depth=1\n",
    "    hp.logmode = False\n",
    "    hp.steps_between_learnings = 100\n",
    "    hp.save_path = 'saved_runs'\n",
    "    hp.this_run_name = sys.argv[0] + '_noname_' + str(int(time.time()))\n",
    "    hp.description = \"real life syclop, fixed fovea proportions\"\n",
    "    hp.mem_depth = 1\n",
    "    hp.max_episode =  10000\n",
    "    hp.steps_per_episode = 1000\n",
    "    hp.steps_between_learnings = 100\n",
    "    hp.fading_mem = 0.5\n",
    "    recorder_file = 'records.pkl'\n",
    "    hp_file = 'hp.pkl'\n",
    "    hp.contrast_range = [1.0,1.1]\n",
    "    hp.logmode = False\n",
    "#     recorder = Recorder(n=4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if not os.path.exists(hp.save_path):\n",
    "        os.makedirs(hp.save_path)\n",
    "\n",
    "    hp.this_run_path = hp.save_path+'/'+hp.this_run_name+'/'\n",
    "    if not os.path.exists(hp.this_run_path):\n",
    "        os.makedirs(hp.this_run_path)\n",
    "    else:\n",
    "        error('run name already exists!')\n",
    "\n",
    "\n",
    "\n",
    "    import pickle\n",
    "\n",
    "    sensor = syc.Sensor()\n",
    "    agent = Free_run_agent()\n",
    "\n",
    "    reward = syc.Rewards()\n",
    "    observation_size = 256*4\n",
    "    RL = DeepQNetwork(len(agent.hp.action_space), observation_size*hp.mem_depth,#sensor.frame_size+2,\n",
    "                      reward_decay=0.99,\n",
    "                      e_greedy=0.99,\n",
    "                      e_greedy0=0.99,\n",
    "                      replace_target_iter=10,\n",
    "                      memory_size=100000,\n",
    "                      e_greedy_increment=0.0001,\n",
    "                      learning_rate=0.0025,\n",
    "                      double_q=False,\n",
    "                      dqn_mode=True,\n",
    "                      state_table=np.zeros([1,observation_size*hp.mem_depth])\n",
    "                      )\n",
    "#     RL.dqn.load_nwk_param('saved_runs/run_syclop_lirondb.py_noname_1557658952/best_liron.nwk')\n",
    "#     RL.dqn.load_nwk_param('zhoka.nwk'\n",
    "    RL.dqn.load_nwk_param('saved_runs//usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py_noname_1558948584/tempX_1.nwk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "servo = maestro.Controller(ttyStr='/dev/ttyACM1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "servo.natural_bottom = 8384\n",
    "servo.constrained_top = 7500 - servo.natural_bottom + 7500\n",
    "servo.setRange(1, servo.constrained_top, servo.natural_bottom )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gohome():    \n",
    "    servo.setSpeed(0,0)\n",
    "    servo.setSpeed(1,0)\n",
    "    servo.setTarget(1,7500)     #set speed of servo 1\n",
    "    servo.setTarget(0,5000)  #set servo to move to center position\n",
    "    servo.setSpeed(0,1)\n",
    "    servo.setSpeed(1,1)\n",
    "    time.sleep(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gohome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "servo.moveByVelocity(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_observer(sensor,agent):\n",
    "    if hp.logmode:\n",
    "        normfactor=1.0\n",
    "    else:\n",
    "        normfactor = 1.0/1.0\n",
    "    return normfactor*np.concatenate([relu_up_and_down(sensor.central_dvs_view),\n",
    "            relu_up_and_down(cv2.resize(1.0*sensor.dvs_view, dsize=(16, 16), interpolation=cv2.INTER_AREA))])\n",
    "\n",
    "observation = np.random.uniform(0,1,size=[hp.mem_depth, observation_size])\n",
    "hp.fading_mem = 0.5\n",
    "recorder = Recorder(n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going home!\n",
      "step 0\n",
      "saved best network, mean reward:  0.00031269395939960805\n",
      "saved best network, mean reward:  0.0016101423322504118\n",
      "saved best network, mean reward:  0.007763479614957006\n",
      "saved best network, mean reward:  0.008386700240416352\n",
      "0 1000  running reward    0.0075128401948186905\n",
      "going home!\n",
      "step 1000\n",
      "saved best network, mean reward:  0.010904554021590409\n",
      "saved best network, mean reward:  0.014815953111703561\n",
      "saved best network, mean reward:  0.01585094353939153\n",
      "1 2000  running reward    0.014303839741601989\n",
      "going home!\n",
      "step 2000\n",
      "going home!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3cf97daad4d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m             (pol_events, num_pol_event,\n\u001b[1;32m     37\u001b[0m              special_events, num_special_event) = \\\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"events_hist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt_this\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_prev\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mdt_nom\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0mt_prev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "training = True\n",
    "device = DVS128()\n",
    "\n",
    "\n",
    "device.start_data_stream()\n",
    "# load new config\n",
    "# device.set_bias_from_json(\"./scripts/configs/dvs128_config.json\")\n",
    "# print (device.get_bias())\n",
    "\n",
    "clip_value = 3\n",
    "histrange = [(0, v) for v in (128, 128)]\n",
    "t_prev = time.time()\n",
    "dt_nom = 0.025\n",
    "episode = 0\n",
    "# dt_list = []\n",
    "cnt = 0\n",
    "empty_cnt = 0\n",
    "best_thus_far = 0.0\n",
    "step = 0 \n",
    "observation = np.random.uniform(0,1,size=[hp.mem_depth, observation_size])\n",
    "observation_ = np.random.uniform(0,1,size=[hp.mem_depth, observation_size])\n",
    "running_ave_reward = 0\n",
    "agent.reset()\n",
    "t0 = time.time()\n",
    "for episode in range(hp.max_episode):\n",
    "    gohome()\n",
    "    print('going home!')\n",
    "\n",
    "    observation = 0*local_observer(sensor, agent)\n",
    "    observation_ = 0*local_observer(sensor, agent)\n",
    "    agent.reset()\n",
    "    step_prime=0\n",
    "    while step_prime < hp.steps_per_episode:\n",
    "        t_this = time.time()\n",
    "        try:\n",
    "            (pol_events, num_pol_event,\n",
    "             special_events, num_special_event) = \\\n",
    "                device.get_event(\"events_hist\")\n",
    "            if t_this - t_prev > dt_nom:\n",
    "                    t_prev=t_this\n",
    "                    if num_pol_event != 0:\n",
    "                        img = pol_events[..., 1]-pol_events[..., 0]\n",
    "                        cv2.imshow(\"image\", np.flip(np.flip( img/float(clip_value*2),axis=0),axis=1))\n",
    "\n",
    "                        action = RL.choose_action(observation.reshape([-1]))\n",
    "                        reward.update_rewards(sensor = sensor, agent = agent)\n",
    "                        running_ave_reward = 0.999*running_ave_reward+0.001*reward.reward\n",
    "    #                     reward.update_rewards(sensor = sensor, agent = agent)\n",
    "                        recorder.record([agent.q_ana[0],agent.q_ana[1], agent.qdot[0],agent.qdot[1],reward.reward,RL.epsilon])\n",
    "                        agent.sync_with_servo(servo)\n",
    "                        agent.act(action)\n",
    "                        for orientation in [0,1]:\n",
    "                            servo.moveByVelocity(orientation,(int(np.round(agent.qdot[orientation]))))\n",
    "                        sensor.dvs_view = cv2.resize(1.0*img, dsize=(64, 64))\n",
    "                        #note fixing fovea size\n",
    "                        sensor.central_dvs_view = cv2.resize(1.0*img[64-16:64:16,64-16:64+16], dsize=(16, 16))\n",
    "                        if step_prime == 0:\n",
    "                            sensor.dvs_view *= 0.\n",
    "                            sensor.central_dvs_view *= 0.\n",
    "    #                     print(np.min(sensor.dvs_view ),np.max(sensor.dvs_view ) )\n",
    "                        observation_ *= hp.fading_mem\n",
    "                        observation_ += local_observer(sensor, agent)  # todo: generalize\n",
    "                        if step%1000 ==0:\n",
    "                            print('step',step)\n",
    "                        RL.store_transition(observation.reshape([-1]), action, reward.reward, observation_.reshape([-1]))\n",
    "                        observation = copy.copy(observation_)\n",
    "                        step += 1\n",
    "                        step_prime +=1\n",
    "                        if  (step > 100) and (step % hp.steps_between_learnings == 0):\n",
    "                            t_pre=time.time()\n",
    "#                             RL.learn()\n",
    "                            t_post=time.time()\n",
    "                            if running_ave_reward > best_thus_far:\n",
    "                                best_thus_far = running_ave_reward\n",
    "#                                 RL.dqn.save_nwk_param(hp.this_run_path+'best_live.nwk')\n",
    "                                print('saved best network, mean reward: ', best_thus_far)\n",
    "#                             print('training took', t_post-t_pre)\n",
    "                        if step%10000 ==0:\n",
    "                            recorder.plot()\n",
    "#                             RL.dqn.save_nwk_param(hp.this_run_path+'tempX_1.nwk')\n",
    "                    # debug_policy_plot()\n",
    "                        if step % 100000 == 0:\n",
    "                                recorder.save(hp.this_run_path+recorder_file)\n",
    "                        if step%1000 ==0:\n",
    "                            print(episode,step,' running reward   ',running_ave_reward)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "                device.shutdown()\n",
    "                break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.this_run_path+'best_live.nwk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
